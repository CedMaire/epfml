{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_loader import load_data, DATA_PATH_TEST, DATA_PATH_TRAIN, DATA_PATH_SAMPLE_SUBMISSION_TEST\n",
    "import logistic_regression\n",
    "import gradient_descent\n",
    "import matplotlib.pyplot as plt\n",
    "from label_predictor import predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, tx, ids_train = load_data(DATA_PATH_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, number_of_subset, seed):\n",
    "    rows_num = len(y)\n",
    "    inter = int(rows_num / number_of_subset)\n",
    "    #set the random seed\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(rows_num)\n",
    "\n",
    "    subset_indices = []\n",
    "    for i in range(number_of_subset):\n",
    "        subset_indices.append(indices[i * inter: (i + 1) * inter])\n",
    "    return np.array(subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, tx, k_indices, k, gamma, alpha):\n",
    "    #get the indices of the subsets\n",
    "    test_set = k_indices[k]\n",
    "    train_set = k_indices[~(np.arange(k_indices.shape[0]) == k)].reshape(-1)\n",
    "    \n",
    "    #get the subsets\n",
    "    tx_train = tx[train_set]\n",
    "    y_train = y[train_set]\n",
    "    tx_test = tx[test_set]\n",
    "    y_test = y[test_set]\n",
    "\n",
    "    \n",
    "    w, loss_train = logistic_regression.regularized_logistic_regression_gradient_descent(y_train, tx_train, gamma, 100,alpha)\n",
    "    loss_test = logistic_regression.calculate_loss(y_test, tx_test, w)\n",
    "    y_pred = predict_labels(w, tx_test)\n",
    "    counter = 0\n",
    "    #change the -1 to 0 to match y_test\n",
    "    y_pred = [0 if x==-1 else x for x in y_pred]\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_pred[i] == y_test[i]:\n",
    "            counter += 1\n",
    "    percent = 100*counter/y_test.shape[0]\n",
    "#     print(percent)\n",
    "    return loss_train, loss_test, w, percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(tx, degree):\n",
    "    for idx, x in enumerate(tx.T):\n",
    "        if idx == 0:\n",
    "            arr_out = build_poly_one_column(x, degree)\n",
    "        else:\n",
    "            arr_out = np.c_[arr_out, build_poly_one_column(x, degree)]\n",
    "    return arr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly_one_column(x, degree):\n",
    "    arr = np.zeros((x.shape[0], degree+1))\n",
    "    for degre in range(degree+1):\n",
    "        arr[:,degre] = np.power(x, degre)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (19590,1) and (19590,1) not aligned: 1 (dim 1) != 19590 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-091d8b3efaef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcross_validation_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-091d8b3efaef>\u001b[0m in \u001b[0;36mcross_validation_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;31m#print(percent)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mpercents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e6cad9ef89a9>\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, tx, k_indices, k, gamma, alpha)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularized_logistic_regression_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py\u001b[0m in \u001b[0;36mregularized_logistic_regression_gradient_descent\u001b[1;34m(y, tx, gamma, max_iter, lambd)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py\u001b[0m in \u001b[0;36mcalculate_loss\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#compute the loss for the two classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloss_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mloss_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (19590,1) and (19590,1) not aligned: 1 (dim 1) != 19590 (dim 0)"
     ]
    }
   ],
   "source": [
    "def cross_validation_test():    \n",
    "#     tx_train = np.delete(tx, [5, 12, 15, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30], axis=1)\n",
    "    for y_t, tx_t, id_test in zip(y, tx, ids_train):\n",
    "        # split data in k fold\n",
    "        number_of_subset = 4\n",
    "        subset_indices = build_k_indices(y_t, number_of_subset, 12) #last number is the seed  \n",
    "        percents = []\n",
    "        tx_train = build_poly(tx_t, 2)\n",
    "        for i in range(number_of_subset):\n",
    "            _,_,_, percent = cross_validation(y_t, tx_train, subset_indices, i, 0.5,0.5)\n",
    "            #print(percent)\n",
    "            percents.append(percent)\n",
    "        print(np.mean(percents))\n",
    "\n",
    "cross_validation_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_2 = np.matmul((1 - y).T,(np.log(1 - sigma)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_1 = -np.matmul(y.T,(np.log(sigma)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oui\n",
      "oui\n",
      "bestRatio: 94.73583460949465\n",
      "Set  0\n",
      "bestW  [-0.13355594 -0.13355594 -0.13355594 -0.13355594  0.17675639  0.08146928\n",
      " -0.13355594  0.02794928 -0.46874209 -0.13355594 -0.00423898 -0.05927714\n",
      " -0.13355594 -0.03842175 -0.1961759  -0.13355594 -0.00423926 -0.05927741\n",
      " -0.13355594  0.41947964  0.18235025 -0.13355594 -0.30889708 -0.01150863\n",
      " -0.13355594 -0.051237   -0.00124135 -0.13355594  0.47128012 -0.1389376\n",
      " -0.13355594  0.03245365  0.00316217 -0.13355594 -0.01646251 -0.10537716\n",
      " -0.13355594  0.18534134 -0.20089854 -0.13355594  0.03745565 -0.14220587\n",
      " -0.13355594  0.01336344 -0.075681   -0.13355594  0.24087855  0.07977812\n",
      " -0.13355594  0.02979753 -0.08491963 -0.13355594 -0.02137331 -0.08085034]\n",
      "bestG  0.30000000000000004\n",
      "bestA  0.2\n",
      "bestD  2\n",
      "oui\n",
      "bestRatio: 91.37566137566138\n",
      "Set  1\n",
      "bestW  [-0.0839546  -0.0839546  -0.0839546  -0.0839546   0.16003053 -0.01659541\n",
      " -0.0839546   0.03245236 -0.33187928 -0.0839546  -0.13981232  0.03854788\n",
      " -0.0839546  -0.05039938 -0.18021428 -0.0839546   0.17262087  0.04064369\n",
      " -0.0839546   0.30791306 -0.05215401 -0.0839546  -0.22019134 -0.03953758\n",
      " -0.0839546  -0.15223834  0.03042691 -0.0839546   0.43724962 -0.00160056\n",
      " -0.0839546   0.04253534 -0.02769935 -0.0839546   0.03940018 -0.12983853\n",
      " -0.0839546   0.1326897   0.04595905 -0.0839546   0.02368276 -0.07794429\n",
      " -0.0839546   0.0155788  -0.04843847 -0.0839546   0.14868477  0.03878378\n",
      " -0.0839546  -0.01625841 -0.04729317 -0.0839546  -0.07706785 -0.05870904\n",
      " -0.0839546   0.10940128 -0.05971737 -0.0839546  -0.03087003  0.07535761\n",
      " -0.0839546  -0.02804384 -0.00738625 -0.0839546   0.10940145 -0.05971711]\n",
      "bestG  0.1\n",
      "bestA  0.1\n",
      "bestD  2\n",
      "oui\n",
      "bestRatio: 90.14227642276423\n",
      "Set  2\n",
      "bestW  [-0.05695174 -0.05695174 -0.05695174 -0.05695174  0.04186251  0.02291756\n",
      " -0.05695174 -0.0027215  -0.3730588  -0.05695174 -0.06750877  0.12308587\n",
      " -0.05695174  0.1393673   0.03212818 -0.05695174  0.16430374  0.09487586\n",
      " -0.05695174 -0.05832444  0.07062629 -0.05695174 -0.08906927 -0.28293978\n",
      " -0.05695174  0.52401348  0.02406859 -0.05695174  0.24866817 -0.17556956\n",
      " -0.05695174 -0.21585716 -0.05951522 -0.05695174 -0.11023834  0.1457003\n",
      " -0.05695174  0.16287699  0.14714518 -0.05695174  0.42998065  0.02177171\n",
      " -0.05695174  0.00503211 -0.20848686 -0.05695174 -0.00484899 -0.14249674\n",
      " -0.05695174  0.12365522  0.06221421 -0.05695174  0.00056664 -0.12310966\n",
      " -0.05695174 -0.04802271 -0.04333015 -0.05695174 -0.01001159  0.03014011\n",
      " -0.05695174 -0.03958963  0.01274767 -0.05695174 -0.33219675  0.04141972\n",
      " -0.05695174  0.05680083 -0.07381218 -0.05695174 -0.08840652  0.13667027\n",
      " -0.05695174 -0.03181343 -0.08882429 -0.05695174  0.18301096 -0.02433888\n",
      " -0.05695174  0.01728282 -0.02315761 -0.05695174  0.15440295 -0.06198728\n",
      " -0.05695174  0.10754631 -0.06474109]\n",
      "bestG  0.1\n",
      "bestA  0.1\n",
      "bestD  2\n",
      "oui\n",
      "oui\n",
      "bestRatio: 93.15718157181571\n",
      "Set  3\n",
      "bestW  [-0.20166488 -0.20166488 -0.20166488 -0.20166488  0.3424518  -0.49875555\n",
      " -0.20166488 -0.26198072 -1.34581647 -0.20166488  0.08843921  0.29055524\n",
      " -0.20166488 -0.16416443  0.14862618 -0.20166488  0.10822622 -0.08020958\n",
      " -0.20166488 -0.09459467 -0.04214991 -0.20166488 -0.09562568  0.05807649\n",
      " -0.20166488  0.36172225 -0.1149098  -0.20166488  0.05650842  0.39688253\n",
      " -0.20166488 -0.29031382 -0.35497037 -0.20166488 -0.32728166 -0.12322376\n",
      " -0.20166488  0.10362242  0.32953832 -0.20166488  0.18762396  0.00646969\n",
      " -0.20166488 -0.51802354 -0.30595599 -0.20166488  0.10706052 -0.23634011\n",
      " -0.20166488  0.38840677  0.01132335 -0.20166488 -0.02343103  0.11120843\n",
      " -0.20166488 -0.37230975 -0.00483637 -0.20166488  0.07600964 -0.31482968\n",
      " -0.20166488  0.08478808 -0.14258932 -0.20166488 -0.54625247  0.24297023\n",
      " -0.20166488  0.03386202 -0.28721975 -0.20166488 -0.08077437 -0.30603415\n",
      " -0.20166488 -0.05020589 -0.00811957 -0.20166488  0.0062518  -0.09082845\n",
      " -0.20166488 -0.04223705 -0.33850637 -0.20166488 -0.03905423 -0.00996019\n",
      " -0.20166488 -0.10778165 -0.95672976]\n",
      "bestG  0.5\n",
      "bestA  0.1\n",
      "bestD  2\n",
      "oui\n",
      "oui\n",
      "bestRatio: 79.95337995337997\n",
      "Set  4\n",
      "bestW  [-2.60839565e-02 -2.60839565e-02 -2.60839565e-02 -2.60839565e-02\n",
      " -4.52733549e-01  8.09765593e-02 -2.60839565e-02 -1.91679856e-01\n",
      " -3.83726623e-01 -2.60839565e-02 -5.21649444e-02  6.93176646e-02\n",
      " -2.60839565e-02  5.72333766e-01 -3.47932607e-01 -2.60839565e-02\n",
      " -5.21648568e-02  6.93178828e-02 -2.60839565e-02  2.28108756e-01\n",
      " -1.10624561e-02 -2.60839565e-02 -4.49128847e-01  8.51867023e-02\n",
      " -2.60839565e-02 -5.12689726e-03  2.40115644e-02 -2.60839565e-02\n",
      "  4.38842507e-01 -4.11776961e-02 -2.60839565e-02 -3.21092931e-04\n",
      " -9.63071639e-02 -2.60839565e-02  4.19063564e-03 -4.55059260e-03\n",
      " -2.60839565e-02 -8.66263739e-02  2.17133270e-02 -2.60839565e-02\n",
      "  2.57538904e-02 -2.12796654e-01 -2.60839565e-02  4.76833574e-03\n",
      " -1.61627467e-02 -2.60839565e-02 -3.70941295e-01  8.33638740e-02\n",
      " -2.60839565e-02 -3.47767852e-02  4.92000542e-03 -2.60839565e-02\n",
      "  1.42037745e-01 -1.51047329e-02]\n",
      "bestG  0.2\n",
      "bestA  0.1\n",
      "bestD  2\n",
      "oui\n",
      "bestRatio: 76.13603886824808\n",
      "Set  5\n",
      "bestW  [ 0.00304931  0.00304931  0.00304931  0.00304931 -0.43749121 -0.05438995\n",
      "  0.00304931  0.25131467 -0.45982896  0.00304931  0.12756109  0.14150309\n",
      "  0.00304931  0.48586042 -0.52423857  0.00304931  0.06878883 -0.00562666\n",
      "  0.00304931  0.24948772 -0.03288224  0.00304931 -0.24250315 -0.01643099\n",
      "  0.00304931  0.3052609   0.08564706  0.00304931  0.39899185 -0.0148704\n",
      "  0.00304931 -0.00654009 -0.11357864  0.00304931 -0.02021749  0.00478808\n",
      "  0.00304931  0.10115323  0.02336761  0.00304931 -0.00177951 -0.19266665\n",
      "  0.00304931 -0.01380481  0.01737962  0.00304931  0.12479252  0.00798826\n",
      "  0.00304931  0.01336041  0.00422622  0.00304931  0.08775832 -0.06772668\n",
      "  0.00304931  0.13091268  0.02453719  0.00304931 -0.00682448  0.39146664\n",
      "  0.00304931 -0.00766568  0.00978668  0.00304931  0.13091275  0.02453712]\n",
      "bestG  0.1\n",
      "bestA  0.1\n",
      "bestD  2\n",
      "oui\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-55a2945c0dc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_test\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mbestW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_search_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Set \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bestW \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-55a2945c0dc3>\u001b[0m in \u001b[0;36mcross_validation_search_param\u001b[1;34m(tx, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mratios\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                     \u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratios\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestRatio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e6cad9ef89a9>\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, tx, k_indices, k, gamma, alpha)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularized_logistic_regression_gradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py\u001b[0m in \u001b[0;36mregularized_logistic_regression_gradient_descent\u001b[1;34m(y, tx, gamma, max_iter, lambd)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py\u001b[0m in \u001b[0;36mcalculate_gradient\u001b[1;34m(y, tx, w)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#calculate the sigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\benja\\git\\MLProjet\\epfml\\src\\logistic_regression.py\u001b[0m in \u001b[0;36mlogistic_function\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlogistic_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cross_validation_search_param(tx, y):\n",
    "    # split data in k fold\n",
    "    number_of_subset = 4\n",
    "    subset_indices = build_k_indices(y, number_of_subset, 12) #last number is the seed\n",
    "    \n",
    "    #Best parameter\n",
    "    bestW = []\n",
    "    bestRatio = 0\n",
    "    bestG = 0\n",
    "    bestA = 0\n",
    "    bestD = 0\n",
    "    \n",
    "    count = 0\n",
    "    #Test of different degrees\n",
    "    for d in np.arange(2, 3, 1):  \n",
    "        tx_train = build_poly(tx, d)\n",
    "        #Test of different alpha\n",
    "        for a in np.arange(0.1, 1, 0.1):\n",
    "            #Test of different gamma\n",
    "            for g in np.arange(0.1, 1, 0.1):\n",
    "                # define lists to store the ratio of true mapping\n",
    "                ratio = 0\n",
    "                ratios= []\n",
    "                for k in range(number_of_subset):\n",
    "                    _, _, w, ratio = cross_validation(y, tx_train, subset_indices, k, g, a)\n",
    "                    ratios.append(ratio)\n",
    "                if np.mean(ratios) > bestRatio:\n",
    "                    print(\"oui\")\n",
    "                    bestW = w\n",
    "                    bestG = g\n",
    "                    bestA = a\n",
    "                    bestD = d\n",
    "                    bestRatio = np.mean(ratios)\n",
    "                count += 1\n",
    "#                 if(count%100 == 0):\n",
    "#                     print(count)\n",
    "#                 print(\"ratio:\", np.mean(ratios))\n",
    "    print(\"bestRatio:\", bestRatio)\n",
    "    return bestW, bestG, bestA, bestD\n",
    "counter = 0\n",
    "for y_t, tx_t, id_test in zip(y, tx, ids_train):\n",
    "    bestW, bestG, bestA, bestD = cross_validation_search_param(tx_t, y_t)\n",
    "    print(\"Set \", counter)\n",
    "    print(\"bestW \", bestW)\n",
    "    print(\"bestG \", bestG)\n",
    "    print(\"bestA \", bestA)\n",
    "    print(\"bestD \", bestD)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
